import report_utilities as utils

from datetime import date, datetime

import logging

SOURCE_TABLE = 'smart_columbus_cve__captcha'

# Maximum distance in ? from a stop bar for a BSM to be associated with it
DISTANCE_THRESHOLD = '0.00002'

# Maximum deviance in degrees from the lane's heading for a vehicle to be considered in that lane.
HEADING_TOLERANCE = '20'

# Minimum speed in ? for a BSM to be included
SPEED_TOLERANCE = '1.0'

# Maximum difference in seconds between a BSM and its matching SPAT
MESSAGE_TIME_TOLERANCE = '0.05'

def rlr_report_day(cur, os_partition, target):
    map_work_table = "cve_map_python_scratch"
    bsm_work_table = "cve_bsm_python_scratch"
    match_table = "cve_match_python_scratch"
    spat_work_table = "cve_spat_python_scratch"
    final_work_table = "cve_final_python_scratch"

    map_query = f"""
    with latest_map as (SELECT max_by(messagebody, timestamp) as messagebody, sourcedevice FROM {SOURCE_TABLE} where os_partition = '{date.today().strftime("%Y_%m")}' and messagetype = 'MAP' group by sourcedevice),

    extracted_values as (
        select 
            json_extract(messageBody, '$.intersections[0].laneWidth') as laneWidth, 
            cast(json_extract_scalar(messageBody, '$.intersections[0].refPoint.lat') as double) / 10000000 as refLat, 
            cast(json_extract_scalar(messageBody, '$.intersections[0].refPoint.long') as double) / 10000000 as refLon,

            transform(
                cast(json_extract(messageBody, '$.intersections[0].laneSet') AS ARRAY<JSON>),
                    x -> element_at(transform(cast(JSON_EXTRACT(x, '$.nodeList[1]') as ARRAY<JSON>),
                    y -> cast(ROW(
                        JSON_EXTRACT_scalar(x, '$.laneID'), 
                        JSON_EXTRACT_scalar(x, '$.ingressApproach'),
                        cast(transform(cast(JSON_EXTRACT(x, '$.connectsTo') as ARRAY<JSON>), connection -> JSON_EXTRACT_SCALAR(connection, '$.signalGroup')) as ARRAY<VARCHAR>),  
                        JSON_EXTRACT_scalar(y, '$.delta[1].x'), 
                        JSON_EXTRACT_scalar(y, '$.delta[1].y'),
                        JSON_EXTRACT_scalar(x, '$.nodeList[1][1].delta[1].x'), 
                        JSON_EXTRACT_scalar(x, '$.nodeList[1][1].delta[1].y')
                        ) 
                    as ROW(laneID VARCHAR, ingressApproach VARCHAR, signals ARRAY<VARCHAR>, x DOUBLE, y DOUBLE, xOffset DOUBLE, yOffset DOUBLE))
                    ), 1)
                ) as deltas,
        * from latest_map
    ),
        
    extracted_coordinates as (
    select transform(deltas, x -> cast(ROW(
    x.laneID, 
    x.ingressApproach, 
    x.signals,
    refLat + (x.y / 100) / 111111, 
    refLon + (x.x / 100) / (111111 * COS(refLat * PI() / 180)),
    MOD(90 - ATAN2(x.yOffset * -1, x.xOffset * -1)*180/PI(),360)
    ) as ROW(laneID VARCHAR, ingressApproach VARCHAR, signals ARRAY<VARCHAR>, lat DOUBLE, lon DOUBLE, laneDirection DOUBLE))) as coordinates, 
    * from extracted_values
    ),

    stop_points as (
        SELECT ingressApproach, sourcedevice, laneID, signals, lat, lon, CASE WHEN laneDirection < 0 THEN laneDirection + 360 else laneDirection END as laneDirection 
        FROM extracted_coordinates CROSS JOIN UNNEST(coordinates) AS t ( laneID, ingressApproach, signals, lat, lon, laneDirection) 
        where ingressApproach is not null
    )

    select * from stop_points
    """

    bsm_query = f"""
    with bsm_subset as (
        select * from {SOURCE_TABLE} 
        where os_partition = '{os_partition}' 
        and messagetype = 'BSM' 
    ), 

    identified_locations as (
        select 
            cast(json_extract_scalar(messagebody, '$.coreData.lat') as double) / 10000000 as lat, 
            cast(json_extract_scalar(messagebody, '$.coreData.long') as double) / 10000000 as long, 
            json_extract_scalar(messagebody, '$.coreData.id') as id, 
            sourcedevice,
            timestamp, 
            cast(json_extract_scalar(messagebody, '$.coreData.speed') as double) as speed, 
            cast(json_extract(messagebody,'$.coreData.heading') as double) / 80 as heading 
            from bsm_subset
    ),

    bsms_in_range as (
        select il.lat, il.long, il.id, il.timestamp, il.speed, il.heading, il.sourcedevice
        from identified_locations il join {map_work_table} sp on ST_Distance(ST_Point(il.lat, il.long), ST_Point(sp.lat, sp.lon)) < {DISTANCE_THRESHOLD}
        and il.sourcedevice = sp.sourcedevice
    ),

    distance_to_lane as (
        select 
            bsm.id, bsm.lat, bsm.long, laneID, timestamp, speed, sp.laneDirection, heading, bsm.sourcedevice,
            ST_Distance(ST_Point(bsm.lat, bsm.long), ST_Point(sp.lat, sp.lon)) as distance 
        from bsms_in_range bsm join {map_work_table} sp on 1=1
    ),

    bsms as (
        select id, min(distance) as distance, laneID, lat, long, timestamp, speed, laneDirection, heading, sourcedevice
        from distance_to_lane 
        where speed > {SPEED_TOLERANCE} 
        and (
        (abs(heading - lanedirection) < {HEADING_TOLERANCE}) 
        OR (heading > 360 - {HEADING_TOLERANCE} AND heading > laneDirection + 360 - {HEADING_TOLERANCE})
        OR (heading < {HEADING_TOLERANCE} AND heading < laneDirection - 360 + {HEADING_TOLERANCE})
        ) 
        and distance < {DISTANCE_THRESHOLD} 
        group by id, laneID, lat, long, timestamp, speed, laneDirection, heading, sourcedevice
    ),

    min_distance as (select min_by(laneid, distance) as laneid, min(distance) as distance, timestamp, id, lat, long, speed, heading, sourcedevice from bsms group by timestamp, id, lat, long, speed, heading, sourcedevice)

    select 
        min_by(timestamp, distance) as timestamp, 
        min_by(lat, distance) as lat,
        min_by(long, distance) as long,
        min_by(speed, distance) as speed,
        min_by(heading, distance) as heading,
        id, laneid, sourcedevice 
    from min_distance group by id, laneid, sourcedevice
    """

    bsm_to_spat_query = f"""
    with bsms_unix as (
        select timestamp, to_unixtime(from_iso8601_timestamp(timestamp)) as unixtime, sourcedevice, laneid
        from {bsm_work_table}
    ),

    spats_unix as (
        select timestamp, to_unixtime(from_iso8601_timestamp(timestamp)) as unixtime, sourcedevice
        from {SOURCE_TABLE} where os_partition = '{os_partition}' and messagetype = 'SPAT' 
    ),

    unix_join as (
        select bsms.timestamp as bsm_timestamp, spats.timestamp as spat_timestamp, spats.sourcedevice, bsms.laneid
        from spats_unix as spats join bsms_unix as bsms on abs(bsms.unixtime - spats.unixtime) < {MESSAGE_TIME_TOLERANCE} and bsms.sourcedevice = spats.sourcedevice
    ),

    deduped_unix_join as (
        select min(spat_timestamp) as spat_timestamp, bsm_timestamp, sourcedevice, laneid
        from unix_join group by bsm_timestamp, sourcedevice, laneid
    )

    select * from deduped_unix_join
    """

    spat_query = f"""
    with spat_subset as (
        SELECT * FROM {SOURCE_TABLE} 
        where messagetype = 'SPAT' and os_partition = '{os_partition}' 
        and timestamp in (select spat_timestamp from {match_table}) 
    ),

    signal_states as (
        select 
            sourcedevice, 
            timestamp, 
            transform(
                cast(json_extract(messagebody, '$.intersections[0].states') as ARRAY<JSON>), 
                x -> cast(
                        ROW(
                            json_extract(x, '$.signalGroup'), 
                            json_extract(x, '$["state-time-speed"][0].eventState')
                        ) as ROW(signalGroup VARCHAR, state VARCHAR)
                    )
            ) as signalStates 
        from spat_subset
    ),

    extracted_signal_states as (
        select sourceDevice, timestamp, signalGroup, state 
        from signal_states CROSS JOIN UNNEST(signalStates) AS t ( signalGroup, state)
    ),

    lane_signal_groups as (
        select laneID, lat, lon, signalGroup, laneDirection, sourcedevice
        from {map_work_table} CROSS JOIN UNNEST(signals) as t (signalGroup)
    ),

    spat_states as (
        select state, timestamp, laneID, laneDirection, signalGroup, sourcedevice
        from lane_signal_groups join extracted_signal_states using (signalGroup, sourcedevice)
    ),

    spat_truthy_states as (
        select state = 'stop-And-Remain' as signal_group_red, timestamp, laneID, laneDirection, signalGroup, sourcedevice
        from spat_states
    ),

    spat_lane_states as (
        select every(signal_group_red) as lane_red_light, array_agg(signalGroup) as signalGroups, laneID, laneDirection, timestamp, sourcedevice
        from spat_truthy_states group by laneID, timestamp, laneDirection, sourcedevice
    )

    select * from spat_lane_states
    """

    final_query = f"""
    --- Final Result

    select 
        bsms.id, bsms.lat, bsms.long, bsms.timestamp as bsm_timestamp, spat_lane_states.timestamp as spat_timestamp, 
        lane_red_light, dd.laneID, spat_lane_states.laneDirection, bsms.heading, bsms.sourcedevice, bsms.speed * 2.23694 / 50 as speed, array_distinct(spat_lane_states.signalGroups) as signalGroups
    from {bsm_work_table} bsms
    join {match_table} dd on bsms.timestamp = dd.bsm_timestamp and bsms.laneID = dd.laneID
    join {spat_work_table} spat_lane_states on spat_lane_states.timestamp = dd.spat_timestamp and spat_lane_states.laneID = dd.laneID and bsms.sourcedevice = spat_lane_states.sourcedevice
    """

    all_start=datetime.now()

    utils.run_and_save_query(cur, map_query, map_work_table)
    utils.run_and_save_query(cur, bsm_query, bsm_work_table)
    utils.run_and_save_query(cur, bsm_to_spat_query, match_table)
    utils.run_and_save_query(cur, spat_query, spat_work_table)
    utils.run_and_save_query(cur, final_query, final_work_table)

    cur.execute(f'create table if not exists {target} as select * from {final_work_table} limit 0')
    cur.fetchall()

    insert_query = f"""
        insert into {target} select * from {final_work_table}
    """

    cur.execute(insert_query)
    cur.fetchall()

    logging.info(f'Total time: {datetime.now()-all_start}')

cur = utils.new_connection()

for partition in utils.partitions_in_range(date(2020, 10, 16), date.today()):
    rlr_report_day(cur, partition, f"cve_rlr_{partition}")
